---
title: 'STAT 253 Final Project - Classification Models'
author: "Jacob, Julian, Aristo, and Emily"
date: "October 31, 2022"
output: 
  html_document:
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, error=TRUE, message=FALSE, warning=FALSE)
```

# Library Statements 

```{r}
library(ISLR)
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels) 
library(stringr)
library(splitstackshape)
library(tidymodels)
library(lubridate)
library(rpart.plot)
library(cluster)
library(forcats)
tidymodels_prefer()
library(probably) #install.packages('probably')
library(vip)
```

# Read in Data

```{r}
imdb_top_1000 <- read_csv("~/Desktop/Statistical Machine Learning/R Files/Final Project/imdb_top_1000_updated.csv")
```

# Data Cleaning

```{r}
imdb_clean <- imdb_top_1000 %>%
  cSplit("Genre", sep = ",", direction = "wide") %>%
  mutate(Gross = log(revenue))

runtime_clean <- imdb_top_1000$Runtime %>%
  str_replace(" min", "") %>%
  as.numeric()

imdb_clean$Runtime <- runtime_clean

imdb_clean_class <- imdb_clean %>%
  mutate(success_ratio = revenue/budget) %>%
  mutate(flop = as.factor(ifelse(success_ratio > 1, 'FALSE', 'TRUE'))) %>%
  filter(!is.na(flop))

```



# Bagging and Random Forests

```{r}
# Model Specification
rf_spec <- rand_forest() %>%
  set_engine(engine = 'ranger') %>% 
  set_args(mtry = 4, # size of random subset of variables; default is floor(sqrt(number of total predictors))
           trees = 1000, # Number of trees
           min_n = NULL,
           probability = FALSE, # FALSE: get hard predictions (not needed for regression)
           importance = 'impurity') %>% # we'll come back to this at the end
  set_mode('classification') # change this for regression

# Recipe
data_rec <- recipe(flop ~ No_of_Votes, data = imdb_clean_class) %>%
  step_naomit()

# Workflows
data_wf_mtry5 <- workflow() %>%
  add_model(rf_spec %>% set_args(min_n = 5)) %>%
  add_recipe(data_rec) 

## Create workflows for min_n = 10, 25, and 50

data_wf_mtry10 <- workflow() %>%
  add_model(rf_spec %>% set_args(min_n = 10)) %>%
  add_recipe(data_rec)

data_wf_mtry25 <- workflow() %>%
  add_model(rf_spec %>% set_args(min_n = 25)) %>%
  add_recipe(data_rec)

data_wf_mtry50 <- workflow() %>%
  add_model(rf_spec %>% set_args(min_n = 50)) %>%
  add_recipe(data_rec)
```

```{r}
# Fit Models
set.seed(123) # make sure to run this before each fit so that you have the same 1000 trees
data_fit_mtry5 <- fit(data_wf_mtry5, data = imdb_clean_class)

# Fit models for 10, 25, and 50
set.seed(123) 
data_fit_mtry10 <- fit(data_wf_mtry10, data = imdb_clean_class)

set.seed(123)
data_fit_mtry25 <- fit(data_wf_mtry25, data = imdb_clean_class)

set.seed(123) 
data_fit_mtry50 <- fit(data_wf_mtry50, data = imdb_clean_class)
```

```{r}
# Custom Function to get OOB predictions, true observed outcomes and add a user-provided model label
rf_OOB_output <- function(fit_model, model_label, truth){
    tibble(
          .pred_class = fit_model %>% extract_fit_engine() %>% pluck('predictions'), #OOB predictions
          class = truth,
          label = model_label
      )
}
```

```{r}
# Evaluate OOB Metrics

data_rf_OOB_output <- bind_rows(
    rf_OOB_output(data_fit_mtry5,5, imdb_clean_class %>% pull(flop)),
    rf_OOB_output(data_fit_mtry10,10, imdb_clean_class %>% pull(flop)),
    rf_OOB_output(data_fit_mtry25,25, imdb_clean_class %>% pull(flop)),
    rf_OOB_output(data_fit_mtry50,50, imdb_clean_class %>% pull(flop))
)


data_rf_OOB_output %>% 
    group_by(label) %>%
    accuracy(truth = class, estimate = .pred_class)
```

### Evaluating the Forest

```{r}
rf_OOB_output(data_fit_mtry50,50, imdb_clean_class %>% pull(flop)) %>%
    conf_mat(truth = class, estimate= .pred_class)
```

### Variable Importance

```{r}
# Impurity

model_output <-data_fit_mtry50 %>% 
    extract_fit_engine() 

model_output %>% 
    vip(num_features = 10) + theme_classic() #based on impurity, 10 meaning the top 10

model_output %>% vip::vi() %>% head()
model_output %>% vip::vi() %>% tail()
```

```{r}
# Permutation

model_output2 <- data_wf_mtry50 %>% 
  update_model(rf_spec %>% set_args(importance = "permutation")) %>% #based on permutation
  fit(data = imdb_clean_class) %>% 
    extract_fit_engine() 

model_output2 %>% 
    vip(num_features = 10) + theme_classic()


model_output2 %>% vip::vi() %>% head()
model_output2 %>% vip::vi() %>% tail()
```











